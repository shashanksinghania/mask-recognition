{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.3.0.36-cp37-cp37m-win_amd64.whl (33.4 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from opencv-python) (1.18.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.3.0.36\n",
      "Collecting pytest-shutil\n",
      "  Downloading pytest_shutil-1.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting path.py\n",
      "  Downloading path.py-12.4.0-py3-none-any.whl (2.3 kB)\n",
      "Requirement already satisfied: pytest in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (5.3.5)\n",
      "Requirement already satisfied: six in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.14.0)\n",
      "Requirement already satisfied: mock in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (4.0.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.1.0)\n",
      "Collecting execnet\n",
      "  Downloading execnet-1.7.1-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: contextlib2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (0.6.0.post1)\n",
      "Requirement already satisfied: path<13.2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from path.py->pytest-shutil) (13.1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.8.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.5.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.4.3)\n",
      "Collecting apipkg>=1.4\n",
      "  Downloading apipkg-1.5-py2.py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from packaging->pytest->pytest-shutil) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->pytest-shutil) (2.2.0)\n",
      "Installing collected packages: path.py, apipkg, execnet, pytest-shutil\n",
      "Successfully installed apipkg-1.5 execnet-1.7.1 path.py-12.4.0 pytest-shutil-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install pytest-shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of images in our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../dataset/with_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-035ccb8bd387>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of images with mask used: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../dataset/with_mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of images without mask used: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../dataset/without_mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../dataset/with_mask'"
     ]
    }
   ],
   "source": [
    "print(\"Number of images with mask used: \", len(os.listdir('../dataset/with_mask')))\n",
    "print(\"Number of images without mask used: \", len(os.listdir('../dataset/without_mask')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(source, train, test, test_size):\n",
    "    data = os.listdir(source)\n",
    "    train_size = int(len(data)*(1 - test_size))\n",
    "    shuffled_data = random.sample(data, len(data))\n",
    "    training_data = shuffled_data[:train_size]\n",
    "    testing_data = shuffled_data[train_size:]\n",
    "    \n",
    "    # make new folders train and test\n",
    "    for img in training_data:\n",
    "        temp_image = source+img\n",
    "        train_image = train+img\n",
    "        copyfile(temp_image, train_image)\n",
    "    \n",
    "    for img in testing_data:\n",
    "        temp_image = source+img\n",
    "        test_image = test+img\n",
    "        copyfile(temp_image, test_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_SOURCE = '../dataset/with_mask/'\n",
    "TRAIN_MASK_SOURCE = '../dataset/train/yes/'\n",
    "TEST_MASK_SOURCE = '../dataset/test/yes/'\n",
    "\n",
    "NO_MASK_SOURCE = '../dataset/without_mask/'\n",
    "TEST_NO_MASK_SOURCE = '../dataset/test/no/'\n",
    "TRAIN_NO_MASK_SOURCE = '../dataset/train/no/'\n",
    "\n",
    "split_data(MASK_SOURCE, TRAIN_MASK_SOURCE, TEST_MASK_SOURCE, 0.2)\n",
    "split_data(NO_MASK_SOURCE, TRAIN_NO_MASK_SOURCE, TEST_NO_MASK_SOURCE, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training with mask:  635\n",
      "Number of training without mask:  565\n",
      "Number of testing with mask:  159\n",
      "Number of testing without mask:  142\n"
     ]
    }
   ],
   "source": [
    "print('Number of training with mask: ', len(os.listdir(TRAIN_MASK_SOURCE)))\n",
    "print('Number of training without mask: ', len(os.listdir(TRAIN_NO_MASK_SOURCE)))\n",
    "print('Number of testing with mask: ', len(os.listdir(TEST_MASK_SOURCE)))\n",
    "print('Number of testing without mask: ', len(os.listdir(TEST_NO_MASK_SOURCE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = '../dataset/train/'\n",
    "TEST_DIR = '../dataset/test/'\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                 target_size = (150,150),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                            target_size = (150,150),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shashank\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shashank\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to get best weights with monitored with validation loss\n",
    "checkpoint = ModelCheckpoint('C:/Users/Shashank/Documents/projects/mask-recognition/.ipynb_checkpoints/models_checkpoints/model-{epoch:03d}.model', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 57s 2s/step - loss: 0.6991 - acc: 0.6667 - val_loss: 0.3566 - val_acc: 0.8439\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 61s 2s/step - loss: 0.3956 - acc: 0.8433 - val_loss: 0.2693 - val_acc: 0.9003\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 59s 2s/step - loss: 0.3325 - acc: 0.8725 - val_loss: 0.2201 - val_acc: 0.9037\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.2695 - acc: 0.8925 - val_loss: 0.1833 - val_acc: 0.9169\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.2806 - acc: 0.8950 - val_loss: 0.1476 - val_acc: 0.9302\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.3015 - acc: 0.8742 - val_loss: 0.1527 - val_acc: 0.9302\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.2559 - acc: 0.9058 - val_loss: 0.1589 - val_acc: 0.9269\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.2332 - acc: 0.9133 - val_loss: 0.1661 - val_acc: 0.9236\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1966 - acc: 0.9117 - val_loss: 0.1645 - val_acc: 0.9236\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.2192 - acc: 0.9108 - val_loss: 0.1509 - val_acc: 0.9369\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.2109 - acc: 0.9175 - val_loss: 0.1301 - val_acc: 0.9635\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.1830 - acc: 0.9250 - val_loss: 0.1498 - val_acc: 0.9468\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1826 - acc: 0.9292 - val_loss: 0.1797 - val_acc: 0.9269\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.2017 - acc: 0.9233 - val_loss: 0.1292 - val_acc: 0.9468\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1922 - acc: 0.9233 - val_loss: 0.1608 - val_acc: 0.9369\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1687 - acc: 0.9358 - val_loss: 0.1639 - val_acc: 0.9502\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1852 - acc: 0.9292 - val_loss: 0.1293 - val_acc: 0.9535\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 50s 1s/step - loss: 0.1632 - acc: 0.9425 - val_loss: 0.1431 - val_acc: 0.9635\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.2205 - acc: 0.9175 - val_loss: 0.1541 - val_acc: 0.9435\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1614 - acc: 0.9317 - val_loss: 0.1097 - val_acc: 0.9601\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1713 - acc: 0.9308 - val_loss: 0.1219 - val_acc: 0.9535\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1533 - acc: 0.9308 - val_loss: 0.1165 - val_acc: 0.9635\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1350 - acc: 0.9500 - val_loss: 0.1263 - val_acc: 0.9601\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 62s 2s/step - loss: 0.1414 - acc: 0.9400 - val_loss: 0.1362 - val_acc: 0.9535\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.1441 - acc: 0.9392 - val_loss: 0.1182 - val_acc: 0.9502\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1575 - acc: 0.9333 - val_loss: 0.1117 - val_acc: 0.9668\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1365 - acc: 0.9517 - val_loss: 0.1105 - val_acc: 0.9535\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1300 - acc: 0.9475 - val_loss: 0.1502 - val_acc: 0.9568\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1447 - acc: 0.9433 - val_loss: 0.1232 - val_acc: 0.9568\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 55s 1s/step - loss: 0.1504 - acc: 0.9417 - val_loss: 0.1113 - val_acc: 0.9635\n"
     ]
    }
   ],
   "source": [
    "# To train the modek on your computer and dataset\n",
    "model = cnn.fit(x = training_set, validation_data = test_set, epochs = 30, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4b20e281d7d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# To save the model in your disk\n",
    "'''\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = cnn.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this to directly load the trained model if you don't wish to train it on your computer\n",
    "\n",
    "# load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "\n",
    "# load weights into new model\n",
    "cnn.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model on webcam input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['No Mask :/', 'Mask On!']\n",
    "grid_color = [(0, 0, 255), (255, 0, 0)]\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "classifier = cv2.CascadeClassifier('C:/Users/Shashank/anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "try: \n",
    "    while webcam.isOpened():\n",
    "        _, frame = webcam.read()\n",
    "        frame = cv2.flip(frame, 1, 1)\n",
    "        faces = classifier.detectMultiScale(frame, 1.1, 4)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "#             cv2.putText(frame, labels[answer], (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n",
    "            face = frame[y-40:y+h+20, x-20:x+w+20]\n",
    "            resized_data = (cv2.resize(face, (150, 150)))/255.0\n",
    "            final_data = np.expand_dims(resized_data, axis = 0)\n",
    "            prediction = cnn.predict(final_data)\n",
    "            answer = int(prediction[0][0] < 0.4) #Binary answer 0 = no, 1 = yes\n",
    "\n",
    "            # display the answer\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), grid_color[answer], 3)\n",
    "            cv2.rectangle(frame, (x-2, y-45), (x+w,y), grid_color[answer], -1)\n",
    "            cv2.putText(frame, labels[answer], (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"MASK DETECTOR\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "except:\n",
    "    raise\n",
    "    \n",
    "finally:        \n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Without Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask on\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('test_data/img7.jpg', target_size = (150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(resized_data, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "res = \"Mask on\" if (result[0][0]>0.4) else \"Mask off\" \n",
    "print(res)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
