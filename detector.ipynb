{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\shashank\\anaconda3\\lib\\site-packages (4.3.0.36)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from opencv-python) (1.18.1)\n",
      "Requirement already satisfied: pytest-shutil in c:\\users\\shashank\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: path.py in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (12.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.14.0)\n",
      "Requirement already satisfied: contextlib2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (0.6.0.post1)\n",
      "Requirement already satisfied: execnet in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.7.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (5.3.5)\n",
      "Requirement already satisfied: termcolor in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.1.0)\n",
      "Requirement already satisfied: mock in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (4.0.1)\n",
      "Requirement already satisfied: path<13.2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from path.py->pytest-shutil) (13.1.0)\n",
      "Requirement already satisfied: apipkg>=1.4 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from execnet->pytest-shutil) (1.5)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.8.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.5.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from packaging->pytest->pytest-shutil) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->pytest-shutil) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install pytest-shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of images in our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images with mask used:  794\n",
      "Number of images without mask used:  707\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images with mask used: \", len(os.listdir('../dataset/with_mask')))\n",
    "print(\"Number of images without mask used: \", len(os.listdir('../dataset/without_mask')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(source, train, test, test_size):\n",
    "    data = os.listdir(source)\n",
    "    train_size = int(len(data)*(1 - test_size))\n",
    "    shuffled_data = random.sample(data, len(data))\n",
    "    training_data = shuffled_data[:train_size]\n",
    "    testing_data = shuffled_data[train_size:]\n",
    "    \n",
    "    # make new folders train and test\n",
    "    for img in training_data:\n",
    "        temp_image = source+img\n",
    "        train_image = train+img\n",
    "        copyfile(temp_image, train_image)\n",
    "    \n",
    "    for img in testing_data:\n",
    "        temp_image = source+img\n",
    "        test_image = test+img\n",
    "        copyfile(temp_image, test_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_SOURCE = '../dataset/with_mask/'\n",
    "TRAIN_MASK_SOURCE = '../dataset/train/yes/'\n",
    "TEST_MASK_SOURCE = '../dataset/test/yes/'\n",
    "\n",
    "NO_MASK_SOURCE = '../dataset/without_mask/'\n",
    "TEST_NO_MASK_SOURCE = '../dataset/test/no/'\n",
    "TRAIN_NO_MASK_SOURCE = '../dataset/train/no/'\n",
    "\n",
    "split_data(MASK_SOURCE, TRAIN_MASK_SOURCE, TEST_MASK_SOURCE, 0.2)\n",
    "split_data(NO_MASK_SOURCE, TRAIN_NO_MASK_SOURCE, TEST_NO_MASK_SOURCE, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training with mask:  635\n",
      "Number of training without mask:  565\n",
      "Number of testing with mask:  159\n",
      "Number of testing without mask:  142\n"
     ]
    }
   ],
   "source": [
    "print('Number of training with mask: ', len(os.listdir(TRAIN_MASK_SOURCE)))\n",
    "print('Number of training without mask: ', len(os.listdir(TRAIN_NO_MASK_SOURCE)))\n",
    "print('Number of testing with mask: ', len(os.listdir(TEST_MASK_SOURCE)))\n",
    "print('Number of testing without mask: ', len(os.listdir(TEST_NO_MASK_SOURCE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = '../dataset/train/'\n",
    "TEST_DIR = '../dataset/test/'\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                 target_size = (150,150),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                            target_size = (150,150),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shashank\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shashank\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to get best weights with monitored with validation loss\n",
    "checkpoint = ModelCheckpoint('.ipynb_checkpoints/models_checkpoints/model-{epoch:03d}.model', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 62s 2s/step - loss: 0.1399 - acc: 0.9400 - val_loss: 0.0818 - val_acc: 0.9734\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1465 - acc: 0.9467 - val_loss: 0.0924 - val_acc: 0.9734\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1416 - acc: 0.9408 - val_loss: 0.1029 - val_acc: 0.9701\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1486 - acc: 0.9458 - val_loss: 0.1067 - val_acc: 0.9601\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1280 - acc: 0.9483 - val_loss: 0.0911 - val_acc: 0.9668\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.1606 - acc: 0.9392 - val_loss: 0.0904 - val_acc: 0.9734\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.1358 - acc: 0.9442 - val_loss: 0.0787 - val_acc: 0.9668\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1221 - acc: 0.9567 - val_loss: 0.0804 - val_acc: 0.9734\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 60s 2s/step - loss: 0.1164 - acc: 0.9558 - val_loss: 0.1170 - val_acc: 0.9668\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 63s 2s/step - loss: 0.1150 - acc: 0.9658 - val_loss: 0.0802 - val_acc: 0.9701\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 58s 2s/step - loss: 0.1169 - acc: 0.9533 - val_loss: 0.1015 - val_acc: 0.9668\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 59s 2s/step - loss: 0.1554 - acc: 0.9425 - val_loss: 0.0795 - val_acc: 0.9601\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 63s 2s/step - loss: 0.1165 - acc: 0.9508 - val_loss: 0.0811 - val_acc: 0.9767\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 62s 2s/step - loss: 0.1072 - acc: 0.9592 - val_loss: 0.0876 - val_acc: 0.9834\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 67s 2s/step - loss: 0.1106 - acc: 0.9567 - val_loss: 0.0753 - val_acc: 0.9701\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 55s 1s/step - loss: 0.1104 - acc: 0.9550 - val_loss: 0.0762 - val_acc: 0.9635\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.0995 - acc: 0.9558 - val_loss: 0.0707 - val_acc: 0.9734\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.1311 - acc: 0.9475 - val_loss: 0.0930 - val_acc: 0.9568\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 57s 1s/step - loss: 0.1025 - acc: 0.9658 - val_loss: 0.0668 - val_acc: 0.9734\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1154 - acc: 0.9558 - val_loss: 0.0986 - val_acc: 0.9568\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1163 - acc: 0.9533 - val_loss: 0.1110 - val_acc: 0.9668\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1540 - acc: 0.9433 - val_loss: 0.1746 - val_acc: 0.9402\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1293 - acc: 0.9492 - val_loss: 0.0989 - val_acc: 0.9734\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.1225 - acc: 0.9550 - val_loss: 0.1248 - val_acc: 0.9668\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 55s 1s/step - loss: 0.0990 - acc: 0.9575 - val_loss: 0.0834 - val_acc: 0.9635\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.0828 - acc: 0.9658 - val_loss: 0.0722 - val_acc: 0.9668\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1032 - acc: 0.9608 - val_loss: 0.0700 - val_acc: 0.9767\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1389 - acc: 0.9467 - val_loss: 0.1017 - val_acc: 0.9635\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1264 - acc: 0.9483 - val_loss: 0.0779 - val_acc: 0.9734\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1013 - acc: 0.9575 - val_loss: 0.0749 - val_acc: 0.9701\n"
     ]
    }
   ],
   "source": [
    "# To train the modek on your computer and dataset\n",
    "model = cnn.fit(x = training_set, validation_data = test_set, epochs = 30, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0, 'yes': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# serialize model to JSON\\nmodel_json = cnn.to_json()\\nwith open(\"model.json\", \"w\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\ncnn.save_weights(\"model.h5\")\\nprint(\"Saved model to disk\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save the model in your disk\n",
    "'''\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = cnn.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this to directly load the trained model if you don't wish to train it on your computer\n",
    "\n",
    "# load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "\n",
    "# load weights into new model\n",
    "cnn.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model on webcam input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press esc or q to quit\n"
     ]
    }
   ],
   "source": [
    "labels = ['No Mask :/', 'Mask On!', 'By Shashank Singhaina']\n",
    "grid_color = [(0, 0, 255), (255, 0, 0)]\n",
    "\n",
    "print(\"Press esc or q to quit\")\n",
    "\n",
    "# If you have multiple webcameras, feel free to change the source\n",
    "# 0 is for default camera...\n",
    "# 1 is for secondary camera...\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "classifier = cv2.CascadeClassifier('C:/Users/Shashank/anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "try: \n",
    "    while webcam.isOpened():\n",
    "        _, frame = webcam.read()\n",
    "        frame = cv2.flip(frame, 1, 1)\n",
    "        faces = classifier.detectMultiScale(frame, 1.1, 4)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            face = frame[y-40:y+h+20, x-20:x+w+20]\n",
    "            try:\n",
    "                resized_data = (cv2.resize(face, (150, 150)))/255.0\n",
    "            except Exception as e:\n",
    "                resized_data = (cv2.resize(frame, (150, 150)))/255.0\n",
    "            final_data = np.expand_dims(resized_data, axis = 0)\n",
    "            prediction = cnn.predict(final_data)\n",
    "            answer = prediction[0][0] #Binary answer 0 = no, 1 = yes\n",
    "            # print(answer)\n",
    "            answer = int(answer < 0.2) #Can be changed according to your picture\n",
    "            \n",
    "            \n",
    "            # display the answer\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), grid_color[answer], 3)\n",
    "            cv2.rectangle(frame, (x-2, y-45), (x+w,y), grid_color[answer], -1)\n",
    "            cv2.putText(frame, labels[answer], (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, labels[2], (250 ,470), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0), 1)\n",
    "\n",
    "        cv2.imshow(\"MASK DETECTOR - by SHASHANK SINGHANIA\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27 or (key & 0xFF == ord('q')):\n",
    "            break\n",
    "except:\n",
    "    raise\n",
    "    \n",
    "finally:        \n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Without Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Mask on\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('test_data/img4.jpg', target_size = (150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "print(result[0][0])\n",
    "res = \"Mask on\" if (result[0][0]>0.4) else \"Mask off\" \n",
    "print(res)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
