{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\shashank\\anaconda3\\lib\\site-packages (4.3.0.36)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from opencv-python) (1.18.1)\n",
      "Requirement already satisfied: pytest-shutil in c:\\users\\shashank\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.1.0)\n",
      "Requirement already satisfied: path.py in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (12.4.0)\n",
      "Requirement already satisfied: contextlib2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (0.6.0.post1)\n",
      "Requirement already satisfied: six in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.14.0)\n",
      "Requirement already satisfied: execnet in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (1.7.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (5.3.5)\n",
      "Requirement already satisfied: mock in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest-shutil) (4.0.1)\n",
      "Requirement already satisfied: path<13.2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from path.py->pytest-shutil) (13.1.0)\n",
      "Requirement already satisfied: apipkg>=1.4 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from execnet->pytest-shutil) (1.5)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.8.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.5.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from pytest->pytest-shutil) (0.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from packaging->pytest->pytest-shutil) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\shashank\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->pytest-shutil) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install pytest-shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of images in our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images with mask used:  794\n",
      "Number of images without mask used:  707\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images with mask used: \", len(os.listdir('../dataset/with_mask')))\n",
    "print(\"Number of images without mask used: \", len(os.listdir('../dataset/without_mask')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(source, train, test, test_size):\n",
    "    data = os.listdir(source)\n",
    "    train_size = int(len(data)*(1 - test_size))\n",
    "    shuffled_data = random.sample(data, len(data))\n",
    "    training_data = shuffled_data[:train_size]\n",
    "    testing_data = shuffled_data[train_size:]\n",
    "    \n",
    "    # make new folders train and test\n",
    "    for img in training_data:\n",
    "        temp_image = source+img\n",
    "        train_image = train+img\n",
    "        copyfile(temp_image, train_image)\n",
    "    \n",
    "    for img in testing_data:\n",
    "        temp_image = source+img\n",
    "        test_image = test+img\n",
    "        copyfile(temp_image, test_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_SOURCE = '../dataset/with_mask/'\n",
    "TRAIN_MASK_SOURCE = '../dataset/train/yes/'\n",
    "TEST_MASK_SOURCE = '../dataset/test/yes/'\n",
    "\n",
    "NO_MASK_SOURCE = '../dataset/without_mask/'\n",
    "TEST_NO_MASK_SOURCE = '../dataset/test/no/'\n",
    "TRAIN_NO_MASK_SOURCE = '../dataset/train/no/'\n",
    "\n",
    "split_data(MASK_SOURCE, TRAIN_MASK_SOURCE, TEST_MASK_SOURCE, 0.2)\n",
    "split_data(NO_MASK_SOURCE, TRAIN_NO_MASK_SOURCE, TEST_NO_MASK_SOURCE, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training with mask:  635\n",
      "Number of training without mask:  565\n",
      "Number of testing with mask:  159\n",
      "Number of testing without mask:  142\n"
     ]
    }
   ],
   "source": [
    "print('Number of training with mask: ', len(os.listdir(TRAIN_MASK_SOURCE)))\n",
    "print('Number of training without mask: ', len(os.listdir(TRAIN_NO_MASK_SOURCE)))\n",
    "print('Number of testing with mask: ', len(os.listdir(TEST_MASK_SOURCE)))\n",
    "print('Number of testing without mask: ', len(os.listdir(TEST_NO_MASK_SOURCE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = '../dataset/train/'\n",
    "TEST_DIR = '../dataset/test/'\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                 target_size = (150,150),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                            target_size = (150,150),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to get best weights with monitored with validation loss\n",
    "checkpoint = ModelCheckpoint('C:/Users/Shashank/Documents/projects/mask-recognition/.ipynb_checkpoints/models_checkpoints/model-{epoch:03d}.model', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 57s 2s/step - loss: 0.6991 - acc: 0.6667 - val_loss: 0.3566 - val_acc: 0.8439\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 61s 2s/step - loss: 0.3956 - acc: 0.8433 - val_loss: 0.2693 - val_acc: 0.9003\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 59s 2s/step - loss: 0.3325 - acc: 0.8725 - val_loss: 0.2201 - val_acc: 0.9037\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.2695 - acc: 0.8925 - val_loss: 0.1833 - val_acc: 0.9169\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.2806 - acc: 0.8950 - val_loss: 0.1476 - val_acc: 0.9302\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.3015 - acc: 0.8742 - val_loss: 0.1527 - val_acc: 0.9302\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.2559 - acc: 0.9058 - val_loss: 0.1589 - val_acc: 0.9269\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.2332 - acc: 0.9133 - val_loss: 0.1661 - val_acc: 0.9236\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1966 - acc: 0.9117 - val_loss: 0.1645 - val_acc: 0.9236\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.2192 - acc: 0.9108 - val_loss: 0.1509 - val_acc: 0.9369\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.2109 - acc: 0.9175 - val_loss: 0.1301 - val_acc: 0.9635\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.1830 - acc: 0.9250 - val_loss: 0.1498 - val_acc: 0.9468\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1826 - acc: 0.9292 - val_loss: 0.1797 - val_acc: 0.9269\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.2017 - acc: 0.9233 - val_loss: 0.1292 - val_acc: 0.9468\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1922 - acc: 0.9233 - val_loss: 0.1608 - val_acc: 0.9369\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1687 - acc: 0.9358 - val_loss: 0.1639 - val_acc: 0.9502\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1852 - acc: 0.9292 - val_loss: 0.1293 - val_acc: 0.9535\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 50s 1s/step - loss: 0.1632 - acc: 0.9425 - val_loss: 0.1431 - val_acc: 0.9635\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.2205 - acc: 0.9175 - val_loss: 0.1541 - val_acc: 0.9435\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1614 - acc: 0.9317 - val_loss: 0.1097 - val_acc: 0.9601\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1713 - acc: 0.9308 - val_loss: 0.1219 - val_acc: 0.9535\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1533 - acc: 0.9308 - val_loss: 0.1165 - val_acc: 0.9635\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1350 - acc: 0.9500 - val_loss: 0.1263 - val_acc: 0.9601\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 62s 2s/step - loss: 0.1414 - acc: 0.9400 - val_loss: 0.1362 - val_acc: 0.9535\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.1441 - acc: 0.9392 - val_loss: 0.1182 - val_acc: 0.9502\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.1575 - acc: 0.9333 - val_loss: 0.1117 - val_acc: 0.9668\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1365 - acc: 0.9517 - val_loss: 0.1105 - val_acc: 0.9535\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.1300 - acc: 0.9475 - val_loss: 0.1502 - val_acc: 0.9568\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.1447 - acc: 0.9433 - val_loss: 0.1232 - val_acc: 0.9568\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 55s 1s/step - loss: 0.1504 - acc: 0.9417 - val_loss: 0.1113 - val_acc: 0.9635\n"
     ]
    }
   ],
   "source": [
    "model = cnn.fit(x = training_set, validation_data = test_set, epochs = 30, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0, 'yes': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# To save the model in your disk\n",
    "'''\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = cnn.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# load json and create model\\n\\njson_file = open(\\'model.json\\', \\'r\\')\\nloaded_model_json = json_file.read()\\njson_file.close()\\nloaded_model = model_from_json(loaded_model_json)\\nload weights into new model\\ncnn.load_weights(\"model.h5\")\\nprint(\"Loaded model from disk\")\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment this to directly load the trained model if you don't wish to train it on your computer\n",
    "'''\n",
    "# load json and create model\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "load weights into new model\n",
    "cnn.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model on webcam input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['No Mask, please put it on...', 'Mask On!']\n",
    "grid_color = [(0, 0, 255), (255, 0, 0)]\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "classifier = cv2.CascadeClassifier('C:/Users/Shashank/anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "try: \n",
    "    while webcam.isOpened():\n",
    "        _, frame = webcam.read()\n",
    "        frame = cv2.flip(frame, 1, 1)\n",
    "        faces = classifier.detectMultiScale(frame, 1.1, 4)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            face = frame[y:y+h+20, x:x+w+20]\n",
    "            resized_data = (cv2.resize(face, (150, 150)))/255.0\n",
    "            final_data = np.expand_dims(resized_data, axis = 0)\n",
    "            prediction = cnn.predict(final_data)\n",
    "            answer = int(prediction[0][0]) #Binary answer 0 = no, 1 = yes\n",
    "\n",
    "            # display the answer\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), grid_color[answer], 3)\n",
    "            cv2.rectangle(frame, (x, y-40), (x+w,y), grid_color[answer], -1)\n",
    "            cv2.putText(frame, labels[answer], (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"MASK DETECTOR\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "except err:\n",
    "    raise err\n",
    "    \n",
    "finally:        \n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
